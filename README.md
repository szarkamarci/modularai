# ModularAI - Grocery Store AI System

A scalable, domain-adaptable AI framework for intelligent retail systems. This instance implements a full-stack grocery store solution with predictive analytics, RAG chatbots, and microservices architecture.

## Architecture

```
modularai/
â”œâ”€â”€ core_services/           # Shared infrastructure
â”‚   â”œâ”€â”€ database/           # DB connection & models
â”‚   â”œâ”€â”€ auth/               # Authentication service
â”‚   â””â”€â”€ rag/                # RAG embedding & retrieval
â”œâ”€â”€ domain_services/
â”‚   â””â”€â”€ grocery/            # Grocery business logic
â”‚       â”œâ”€â”€ api/            # FastAPI routes
â”‚       â”œâ”€â”€ models/         # SQLModel schemas
â”‚       â”œâ”€â”€ ml_pipelines/   # Demand forecasting, inventory prediction
â”‚       â””â”€â”€ main.py         # Service entrypoint
â”œâ”€â”€ webui/
â”‚   â”œâ”€â”€ manager_dashboard/  # Vue 3 admin interface
â”‚   â””â”€â”€ ds_workbench/      # Streamlit ML interface
â””â”€â”€ infra/
    â””â”€â”€ docker-compose.yml  # Container setup
```

## Tech Stack

- **Backend**: FastAPI + SQLModel
- **Database**: Supabase (PostgreSQL + Auth + Realtime)
- **Frontend**: Vue 3 + Tailwind CSS
- **ML**: PyTorch, scikit-learn, sentence-transformers
- **RAG**: Local LLM + vector embeddings
- **Deploy**: Docker Compose

## Key Features

**For Store Managers:**
- Inventory dashboard with stock levels and forecasts
- Automated stockout alerts and demand predictions
- Role-based access per store location

**For Data Scientists:**  
- Plug-and-play ML pipelines for demand forecasting
- Real-time transaction data access
- Model experiment tracking

**For Customers:**
- RAG-powered product chatbot
- Semantic product search using embeddings

## Core Models & Data Flow

**Database Models (SQLModel):**
- `Product`: id, name, category, price, stock_level, embeddings
- `Transaction`: id, product_id, quantity, timestamp, store_id
- `Store`: id, name, location, manager_id
- `User`: id, email, role, store_id

**ML Pipelines:**
- Demand forecasting: Historical transactions â†’ Future demand predictions
- Stockout prediction: Current inventory + demand â†’ Alert triggers
- Product embeddings: Product descriptions â†’ Vector representations

**RAG System:**
- Product catalog â†’ Sentence transformer embeddings â†’ Vector store
- User query â†’ Embedding â†’ Similarity search â†’ LLM response

## Environment Setup

```bash
# Required environment variables
SUPABASE_URL=your_supabase_project_url
SUPABASE_ANON_KEY=your_anon_key
SUPABASE_SERVICE_KEY=your_service_key
DATABASE_URL=your_supabase_postgres_url

# ML Models
EMBEDDING_MODEL=all-MiniLM-L6-v2
LLM_MODEL=ollama/llama2

# API Config
API_HOST=0.0.0.0
API_PORT=8000
```

## Quick Start

### ğŸ³ Docker (Recommended)

```bash
# 1. Clone the repository
git clone <your-repo-url>
cd plutusai

# 2. Start all services with Docker Compose
cd infra
docker-compose up -d

# 3. Initialize database (one-time setup)
docker-compose exec grocery-api python -m core_services.database.init_db

# 4. Access applications
# FastAPI Backend: http://localhost:8000
# API Documentation: http://localhost:8000/docs
# Streamlit Demo: http://localhost:8501
# PostgreSQL: localhost:54322
```

### ğŸ”§ Local Development

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Copy environment variables
cp .env.example .env

# 3. Start Supabase locally (optional)
supabase start

# 4. Initialize database
python -m core_services.database.init_db

# 5. Start services
# FastAPI Backend
python -m domain_services.grocery.main

# Streamlit Frontend (in another terminal)
streamlit run webui/ds_workbench/streamlit_app.py
```

## API Endpoints

- `GET /products` - List products with stock levels
- `POST /products/{id}/forecast` - Get demand predictions
- `GET /inventory/alerts` - Current stockout warnings  
- `POST /chat` - RAG chatbot for product queries
- `POST /ml/retrain` - Trigger model retraining

## ğŸ³ Docker Deployment

### Production Deployment
```bash
# Build and start all services
docker-compose -f infra/docker-compose.yml up -d --build

# View logs
docker-compose -f infra/docker-compose.yml logs -f

# Stop services
docker-compose -f infra/docker-compose.yml down
```

### Service Architecture
- **grocery-api**: FastAPI backend (port 8000)
- **ds-workbench**: Streamlit frontend (port 8501)  
- **postgres**: PostgreSQL database (port 54322)
- **manager-dashboard**: Vue.js UI (port 3000) *[planned]*

### Environment Variables
Copy `.env.example` to `.env` and customize:
- Database credentials
- Supabase configuration
- ML model settings

## Development Roadmap

âœ… **Completed:**
- Complete FastAPI backend with SQLModel ORM
- PostgreSQL database with sample data
- Comprehensive API endpoints (products, inventory, chat, ML)
- Streamlit demo frontend with interactive dashboard
- Docker containerization for all services
- Unit tests with 100% pass rate
- Git repository initialization

ğŸš€ **Next Priorities:**
- Vue.js Manager Dashboard UI
- Advanced ML demand forecasting
- RAG chatbot with vector embeddings
- Real-time notifications
- Authentication & authorization
- Manager dashboard completion